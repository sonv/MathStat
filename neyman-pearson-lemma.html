<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.2 Neyman-Pearson Lemma | MATH 310: Mathematical Statistics (brief notes)</title>
  <meta name="description" content="4.2 Neyman-Pearson Lemma | MATH 310: Mathematical Statistics (brief notes)" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="4.2 Neyman-Pearson Lemma | MATH 310: Mathematical Statistics (brief notes)" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.2 Neyman-Pearson Lemma | MATH 310: Mathematical Statistics (brief notes)" />
  
  
  

<meta name="author" content="Truong-Son Van" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="procedure.html"/>
<link rel="next" href="uniformly-most-powerful-test.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<<<<<<< HEAD
<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>
=======
>>>>>>> 3d2f2a799dca0df6bb2985d6f1597118159b568b

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a>Mathematical Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Disclaimer</a></li>
<li class="chapter" data-level="" data-path="syllabus.html"><a href="syllabus.html"><i class="fa fa-check"></i>Syllabus</a>
<ul>
<li class="chapter" data-level="" data-path="syllabus.html"><a href="syllabus.html#key-information"><i class="fa fa-check"></i>Key information</a></li>
<li class="chapter" data-level="" data-path="textbooks-and-references.html"><a href="textbooks-and-references.html"><i class="fa fa-check"></i>Textbooks and references</a>
<ul>
<li class="chapter" data-level="" data-path="textbooks-and-references.html"><a href="textbooks-and-references.html#course-description"><i class="fa fa-check"></i>Course description</a></li>
<li class="chapter" data-level="" data-path="textbooks-and-references.html"><a href="textbooks-and-references.html#learning-objectives"><i class="fa fa-check"></i>Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="assessment.html"><a href="assessment.html"><i class="fa fa-check"></i>Assessment</a></li>
<li class="chapter" data-level="" data-path="core-content.html"><a href="core-content.html"><i class="fa fa-check"></i>Core content</a></li>
<li class="chapter" data-level="" data-path="project-description.html"><a href="project-description.html"><i class="fa fa-check"></i>Project description</a>
<ul>
<li class="chapter" data-level="" data-path="project-description.html"><a href="project-description.html#topics"><i class="fa fa-check"></i>Topics</a></li>
<li class="chapter" data-level="" data-path="project-description.html"><a href="project-description.html#deadlines"><i class="fa fa-check"></i>Deadlines</a></li>
<li class="chapter" data-level="" data-path="project-description.html"><a href="project-description.html#project-guidelines"><i class="fa fa-check"></i>Project Guidelines</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="late-assignments.html"><a href="late-assignments.html"><i class="fa fa-check"></i>Late assignments</a></li>
<li class="chapter" data-level="" data-path="time-expectations.html"><a href="time-expectations.html"><i class="fa fa-check"></i>Time expectations</a>
<ul>
<li class="chapter" data-level="" data-path="time-expectations.html"><a href="time-expectations.html#collaboration-plagiarism"><i class="fa fa-check"></i>Collaboration &amp; Plagiarism</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="learning-support.html"><a href="learning-support.html"><i class="fa fa-check"></i>Learning Support</a></li>
<li class="chapter" data-level="" data-path="wellbeing.html"><a href="wellbeing.html"><i class="fa fa-check"></i>Wellbeing</a></li>
<li class="chapter" data-level="" data-path="tentative-course-schedule.html"><a href="tentative-course-schedule.html"><i class="fa fa-check"></i>Tentative Course Schedule</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-1-background.html"><a href="part-1-background.html"><i class="fa fa-check"></i>PART 1: Background</a></li>
<li class="chapter" data-level="1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>1</b> Probability</a>
<ul>
<li class="chapter" data-level="1.1" data-path="review.html"><a href="review.html"><i class="fa fa-check"></i><b>1.1</b> Review</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="review.html"><a href="review.html#probability-space"><i class="fa fa-check"></i><b>1.1.1</b> Probability Space</a></li>
<li class="chapter" data-level="1.1.2" data-path="review.html"><a href="review.html#random-variables"><i class="fa fa-check"></i><b>1.1.2</b> Random Variables</a></li>
<li class="chapter" data-level="1.1.3" data-path="review.html"><a href="review.html#joint-distribution-of-rvs"><i class="fa fa-check"></i><b>1.1.3</b> Joint distribution of RVs</a></li>
<li class="chapter" data-level="1.1.4" data-path="review.html"><a href="review.html#some-important-random-variables"><i class="fa fa-check"></i><b>1.1.4</b> Some important random variables</a></li>
<li class="chapter" data-level="1.1.5" data-path="review.html"><a href="review.html#independent-random-variables"><i class="fa fa-check"></i><b>1.1.5</b> Independent random variables</a></li>
<li class="chapter" data-level="1.1.6" data-path="review.html"><a href="review.html#transformations-of-rvs"><i class="fa fa-check"></i><b>1.1.6</b> Transformations of RVs</a></li>
<li class="chapter" data-level="1.1.7" data-path="review.html"><a href="review.html#expectation"><i class="fa fa-check"></i><b>1.1.7</b> Expectation</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="moment-generating-and-characteristic-functions.html"><a href="moment-generating-and-characteristic-functions.html"><i class="fa fa-check"></i><b>1.2</b> Moment Generating and Characteristic Functions</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="moment-generating-and-characteristic-functions.html"><a href="moment-generating-and-characteristic-functions.html#moment-generating-functions"><i class="fa fa-check"></i><b>1.2.1</b> Moment Generating Functions</a></li>
<li class="chapter" data-level="1.2.2" data-path="moment-generating-and-characteristic-functions.html"><a href="moment-generating-and-characteristic-functions.html#characteristic-functions"><i class="fa fa-check"></i><b>1.2.2</b> Characteristic Functions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="inequalities.html"><a href="inequalities.html"><i class="fa fa-check"></i><b>1.3</b> Inequalities</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="inequalities.html"><a href="inequalities.html#typical-tail-bound-inequalities"><i class="fa fa-check"></i><b>1.3.1</b> Typical tail bound inequalities</a></li>
<li class="chapter" data-level="1.3.2" data-path="inequalities.html"><a href="inequalities.html#exponential-concentration-inequalities"><i class="fa fa-check"></i><b>1.3.2</b> Exponential concentration inequalities</a></li>
<li class="chapter" data-level="1.3.3" data-path="inequalities.html"><a href="inequalities.html#inequalities-for-expectations"><i class="fa fa-check"></i><b>1.3.3</b> Inequalities for expectations</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html"><i class="fa fa-check"></i><b>1.4</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="1.5" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>1.5</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-2-inference.html"><a href="part-2-inference.html"><i class="fa fa-check"></i>PART 2: Inference</a></li>
<li class="chapter" data-level="2" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>2</b> Sampling</a>
<ul>
<li class="chapter" data-level="2.1" data-path="simple-random-sample.html"><a href="simple-random-sample.html"><i class="fa fa-check"></i><b>2.1</b> Simple Random Sample</a></li>
<li class="chapter" data-level="2.2" data-path="standard-random-sample.html"><a href="standard-random-sample.html"><i class="fa fa-check"></i><b>2.2</b> Standard Random Sample</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="parametric-inference-parameter-estimation.html"><a href="parametric-inference-parameter-estimation.html"><i class="fa fa-check"></i><b>3</b> Parametric Inference (Parameter Estimation)</a>
<ul>
<li class="chapter" data-level="3.1" data-path="point-estimation.html"><a href="point-estimation.html"><i class="fa fa-check"></i><b>3.1</b> Point Estimation</a></li>
<li class="chapter" data-level="3.2" data-path="confidence-set.html"><a href="confidence-set.html"><i class="fa fa-check"></i><b>3.2</b> Confidence set</a></li>
<li class="chapter" data-level="3.3" data-path="method-of-moments.html"><a href="method-of-moments.html"><i class="fa fa-check"></i><b>3.3</b> Method of Moments</a></li>
<li class="chapter" data-level="3.4" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>3.4</b> Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#consistency"><i class="fa fa-check"></i><b>3.4.1</b> Consistency</a></li>
<li class="chapter" data-level="3.4.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#asymptotic-normality"><i class="fa fa-check"></i><b>3.4.2</b> Asymptotic normality</a></li>
<li class="chapter" data-level="3.4.3" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#efficiency"><i class="fa fa-check"></i><b>3.4.3</b> Efficiency</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="optional-expectation-maximization-algorithm.html"><a href="optional-expectation-maximization-algorithm.html"><i class="fa fa-check"></i><b>3.5</b> (Optional) Expectation-Maximization Algorithm</a></li>
<li class="chapter" data-level="3.6" data-path="bayesian-approach.html"><a href="bayesian-approach.html"><i class="fa fa-check"></i><b>3.6</b> Bayesian Approach</a></li>
<li class="chapter" data-level="3.7" data-path="comparing-estimator-decision-theory.html"><a href="comparing-estimator-decision-theory.html"><i class="fa fa-check"></i><b>3.7</b> Comparing Estimator / Decision Theory</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>4</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="4.1" data-path="procedure.html"><a href="procedure.html"><i class="fa fa-check"></i><b>4.1</b> Procedure</a></li>
<<<<<<< HEAD
<li class="chapter" data-level="4.2" data-path="neyman-pearson-lemma.html"><a href="neyman-pearson-lemma.html"><i class="fa fa-check"></i><b>4.2</b> Neyman-Pearson Lemma</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="neyman-pearson-lemma.html"><a href="neyman-pearson-lemma.html#random-test"><i class="fa fa-check"></i><b>4.2.1</b> Randomized Test (Optional)</a></li>
</ul></li>
=======
<li class="chapter" data-level="4.2" data-path="neyman-pearson-lemma.html"><a href="neyman-pearson-lemma.html"><i class="fa fa-check"></i><b>4.2</b> Neyman-Pearson Lemma</a></li>
>>>>>>> 3d2f2a799dca0df6bb2985d6f1597118159b568b
<li class="chapter" data-level="4.3" data-path="uniformly-most-powerful-test.html"><a href="uniformly-most-powerful-test.html"><i class="fa fa-check"></i><b>4.3</b> Uniformly Most Powerful Test</a></li>
<li class="chapter" data-level="4.4" data-path="wald-test.html"><a href="wald-test.html"><i class="fa fa-check"></i><b>4.4</b> Wald Test</a></li>
<li class="chapter" data-level="4.5" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html"><i class="fa fa-check"></i><b>4.5</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="4.6" data-path="comparing-samples.html"><a href="comparing-samples.html"><i class="fa fa-check"></i><b>4.6</b> Comparing samples</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH 310: Mathematical Statistics (brief notes)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="neyman-pearson-lemma" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Neyman-Pearson Lemma<a href="neyman-pearson-lemma.html#neyman-pearson-lemma" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="bbox">
<center>
Assumption throughout this section: both hypotheses are simple.
</center>
</div>
<p>When both the null and alternative hypotheses are simple, we can talk about
the most powerful tests (or the <em>best critical region</em>).</p>
<p>Denote <span class="math inline">\(X = (X_1, \dots, X_n)\)</span> and recall that the space that this lives in
is a state space <span class="math inline">\(S\)</span>.</p>
<div class="definition">
<p><span id="def:unlabeled-div-112" class="definition"><strong>Definition 4.4  </strong></span>Let <span class="math inline">\(C\)</span> be a subset of the state space.
Then we say that <span class="math inline">\(C\)</span> is the <em>best critical region</em> of size <span class="math inline">\(\alpha\)</span> for testing
the simple hypothesis <span class="math inline">\(H_0: \theta = \theta_0\)</span> against the alternative simple
hypothesis <span class="math inline">\(H_1: \theta = \theta_1\)</span> if</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(P_{\theta_0}( (X_1, \dots, X_n) \in C ) = \alpha\)</span></p></li>
<li><p>And for every subset <span class="math inline">\(A\)</span> of the state space
<span class="math display">\[ \mathbb{P}_{\theta_0}( X \in A) = \alpha \implies \mathbb{P}_{\theta_1}(X \in C) \geq \mathbb{P}_{\theta_1} ( X \in A)\]</span></p></li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-113" class="exercise"><strong>Exercise 4.1  (Hogg et. al., 4.5.3) </strong></span>Let <span class="math inline">\(X\)</span> be an RV that has pdf <span class="math inline">\(f(x;\theta) = \theta x^{\theta - 1}\)</span> for <span class="math inline">\(0&lt;x&lt;1\)</span>, zero elsewhere.
Here, <span class="math inline">\(\theta \in \{ 1,2\}\)</span>.
To test the simple hypothesis <span class="math inline">\(H_0: \theta = 1\)</span> against the alternative
simple hypothesis <span class="math inline">\(H_1: \theta = 2\)</span>, use a random sample <span class="math inline">\(X_1, X_2\)</span> of size
<span class="math inline">\(n = 2\)</span> and define the critical region to be <span class="math inline">\(C = \{ x: x_1 x_2 \geq 3/4 \}\)</span>.
Find the power function of the test.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-114" class="exercise"><strong>Exercise 4.2  (Hogg et. al., 4.5.5) </strong></span>Let <span class="math inline">\(X_1, X_2\)</span> be a random sample of size <span class="math inline">\(n=2\)</span> from the distribution having pdf <span class="math inline">\(f(x ; \theta)=(1 / \theta) e^{-x / \theta}, 0&lt;x&lt;\infty\)</span>, zero elsewhere.
Here <span class="math inline">\(\theta \in \{1,2\}\)</span>.
We reject <span class="math inline">\(H_0: \theta=2\)</span> and accept <span class="math inline">\(H_1: \theta=1\)</span> if the observed values of <span class="math inline">\(X_1, X_2\)</span>, say <span class="math inline">\(x_1, x_2\)</span>, are such that
<span class="math display">\[
\frac{f\left(x_1 ; 2\right) f\left(x_2 ; 2\right)}{f\left(x_1 ; 1\right) f\left(x_2 ; 1\right)} \leq \frac{1}{2} .
\]</span></p>
<p>Find the significance level of the test and the power of the test when <span class="math inline">\(H_0\)</span> is false.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-115" class="exercise"><strong>Exercise 4.3  (Hogg et. al., 4.5.9) </strong></span>Let <span class="math inline">\(X\)</span> have a Poisson distribution with mean <span class="math inline">\(\theta\)</span>. Consider the simple hypothesis <span class="math inline">\(H_0: \theta=\frac{1}{2}\)</span> and the alternative composite hypothesis <span class="math inline">\(H_1: \theta&lt;\frac{1}{2}\)</span>. Thus <span class="math inline">\(\Omega=\left\{\theta: 0&lt;\theta \leq \frac{1}{2}\right\}\)</span>. Let <span class="math inline">\(X_1, \ldots, X_{12}\)</span> denote a random sample of size 12 from this distribution. We reject <span class="math inline">\(H_0\)</span> if and only if the observed value of <span class="math inline">\(Y=X_1+\cdots+X_{12} \leq 2\)</span>. Show that the following <span class="math inline">\(\mathrm{R}\)</span> code graphs the power function of this test:</p>
<pre><code>theta =seq(.1, .5, .05)$; gam=ppois(2, theta * 12)
plot (gam theta,pch=&quot; &quot;,xlab=expression(theta),ylab=expression(gamma))
lines (gam ~ theta)</code></pre>
<p>Run the code. Determine the significance level from the plot.</p>
</div>
<div class="example">
<p><span id="exm:critical-region" class="example"><strong>Example 4.2  </strong></span>Consider the following table</p>
<p>Let’s consider the hypothesis test of <span class="math inline">\(H_0: \theta = 1/2\)</span> versus
<span class="math inline">\(H_1: \theta = 3/4\)</span>
with the following probability table:</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(x\)</span></th>
<th align="right">0</th>
<th align="right">1</th>
<th align="right">2</th>
<th align="right">3</th>
<th align="right">4</th>
<th align="right">5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(f(x ; 1 / 2)\)</span></td>
<td align="right"><span class="math inline">\(1 / 32\)</span></td>
<td align="right"><span class="math inline">\(5 / 32\)</span></td>
<td align="right"><span class="math inline">\(10 / 32\)</span></td>
<td align="right"><span class="math inline">\(10/32\)</span></td>
<td align="right"><span class="math inline">\(5/32\)</span></td>
<td align="right"><span class="math inline">\(1/32\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(f(x ; 3 / 4)\)</span></td>
<td align="right"><span class="math inline">\(1 / 1024\)</span></td>
<td align="right"><span class="math inline">\(15 / 1024\)</span></td>
<td align="right"><span class="math inline">\(90 / 1024\)</span></td>
<td align="right"><span class="math inline">\(270/1024\)</span></td>
<td align="right"><span class="math inline">\(405/1024\)</span></td>
<td align="right"><span class="math inline">\(243/1024\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(f(x ; 1 / 2) / f(x ; 3 / 4)\)</span></td>
<td align="right"><span class="math inline">\(32 / 1\)</span></td>
<td align="right"><span class="math inline">\(32 / 3\)</span></td>
<td align="right"><span class="math inline">\(32 / 9\)</span></td>
<td align="right"><span class="math inline">\(32/27\)</span></td>
<td align="right"><span class="math inline">\(32/81\)</span></td>
<td align="right"><span class="math inline">\(32/243\)</span></td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li>Find the critical regions of sizes <span class="math inline">\(1/32\)</span> and <span class="math inline">\(6/32\)</span>.</li>
<li>Find the best critical region of size <span class="math inline">\(1/32\)</span> ad <span class="math inline">\(6/32\)</span>.</li>
<li>Observe what happens to the ratio <span class="math inline">\(f(x;½)/ f(x; ¾)\)</span>.</li>
</ol>
</div>
<p>Recall the likelihood function
<span class="math display">\[\mathcal{L}(\theta;x) = \prod_{i=1}^n f(x_i;\theta)\]</span>
where <span class="math inline">\(x = (x_1, \dots, x_n)\)</span>.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-116" class="theorem"><strong>Theorem 4.1  (baby Neyman-Pearson Theorem) </strong></span>Let <span class="math inline">\(X_1, \dots, X_n\)</span> be a sample from a family of distributions <span class="math inline">\(f(x;\theta)\)</span>,
where <span class="math inline">\(\theta \in \{\theta_0, \theta_1\}\)</span>.
Suppose that <span class="math inline">\(k\)</span> is a positive number and <span class="math inline">\(C\)</span> be a subset of the state space such that</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\displaystyle{\frac{\mathcal{L}(\theta_0;x)}{\mathcal{L}(\theta_1;x)}} \leq k\)</span> for each point <span class="math inline">\(x\in C\)</span>.</li>
<li><span class="math inline">\(\displaystyle\frac{\mathcal{L}(\theta_0;x)}{\mathcal{L}(\theta_1;x)} \geq k\)</span> for each point <span class="math inline">\(x\in C^c\)</span>.</li>
<li><span class="math inline">\(\alpha = P_{\theta_0}(X \in C)\)</span>.</li>
</ol>
<p>Then <span class="math inline">\(C\)</span> is a bests critical region of size <span class="math inline">\(\alpha\)</span> for testing the hypothesis
<span class="math inline">\(H_0: \theta= \theta_0\)</span> against the alternative hypothesis <span class="math inline">\(H_1: \theta = \theta_1\)</span>.</p>
</div>
<div class="bbox">
<p>Note that the above theorem doesn’t mention about the existence of <span class="math inline">\(k\)</span> and <span class="math inline">\(C\)</span>.
This is a conceptual weakness, due to the lack of convexity (surprise!) of deicion rules
based on critical regions. To overcome this, we need to generalize the decision
rules (see Section <a href="neyman-pearson-lemma.html#random-test">4.2.1</a>).</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-117" class="exercise"><strong>Exercise 4.4  (Hogg et. al., 8.1.5) </strong></span>If <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> is a random sample from a distribution having pdf of the form <span class="math inline">\(f(x ; \theta)=\theta x^{\theta-1}, 0&lt;x&lt;1\)</span>, zero elsewhere, show that a best critical region for testing <span class="math inline">\(H_0: \theta=1\)</span> against <span class="math inline">\(H_1: \theta=2\)</span> is <span class="math inline">\(C=\left\{\left(x_1, x_2, \ldots, x_n\right): c \leq \prod_{i=1}^n x_i\right\}\)</span>.</p>
</div>
<p>From Example <a href="neyman-pearson-lemma.html#exm:critical-region">4.2</a>, we see that the best critical region has the
the property that its power is higher than its significance level.
This is interpreted as: the probability of falsely rejecting <span class="math inline">\(H_0\)</span> is less than
the probability of correctly rejecting <span class="math inline">\(H_0\)</span>.
We say that the kind of test (i.e., critical region) that has this property
is <em>unbiased</em>. Formally,</p>
<div class="definition">
<p><span id="def:unlabeled-div-118" class="definition"><strong>Definition 4.5  </strong></span>Let <span class="math inline">\(X \sim f(x;\theta)\)</span>. A test is said to be <em>unbiased</em> if
<span class="math display">\[\inf_{\theta \in D_1} \mathbb{P}_{\theta} (X \in C) \geq \alpha.\]</span></p>
</div>
<div id="random-test" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Randomized Test (Optional)<a href="neyman-pearson-lemma.html#random-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><em>The following discussion is very heuristic. Rigorous justifications
are beyond the level of the class that these notes are intended for.
In particular, we deliberately avoid a technical discussion on regularity of
sets and functions in order to convey the big picture.
Interested readers, who seek rigors, should consult <span class="citation">(<a href="#ref-keener2010theoretical">Keener 2010</a>)</span> and <span class="citation">(<a href="#ref-lehmann2005testing">Lehmann and Romano 2005</a>)</span>.</em></p>
<p>The decision rule so far is very rigid and deterministic: if the sample data
falls into the rejection region, one simply just rejects the null hypothesis.
This way of reasoning is a nice and intuitive.
However, there are some obstacles regarding the rigorous details.
For example, in the (baby) Neyman-Pearson theorem, there is no guarantee that
<span class="math inline">\(k\)</span> and <span class="math inline">\(C\)</span> would exists to satisfy the significance level <span class="math inline">\(\alpha\)</span>.
This is because of the lack of certain convexity in the decision making process.</p>
<p>Take a closer look at the (baby) Pearson-Neyman theorem, we see that</p>
<p>To escape from this predicament, we will first make the following observation:</p>
<p><span class="math display">\[\mathbb{P}_\theta (X \in C) = \mathbb{E}_\theta \varphi(X)\]</span>
where <span class="math inline">\(\varphi\)</span> is the indicator function of <span class="math inline">\(C\)</span>, i.e,
<span class="math display">\[\varphi (x) = \begin{cases} 1 \,, &amp; x \in C \\ 0 \,, &amp; x \in C^c\end{cases} \,.\]</span></p>
<p>Since each set can be represented by its characteristics function, as
each hypothesis test depends on its rejection region, each hypothesis test
can be characterized by <span class="math inline">\(\varphi\)</span>.
It is then customary to talk about a test <span class="math inline">\(\varphi\)</span>.</p>
<p>Denote <span class="math inline">\(\mathcal{D}\)</span> be the set of all characteristic functions associated with
subsets of <span class="math inline">\(\mathbb{R}^n\)</span>.
We can now turn our problem into an optimization problem in the following form:</p>
<p><span class="math display">\[\begin{aligned} &amp; \min_{\varphi \in \mathcal{D}} \mathbb{E}_{\theta_1} \varphi \\
\text{st} \qquad &amp;  \mathbb{E}_{\theta_0} \varphi = \alpha \end{aligned}. \]</span></p>
<p>A problem arises: the set <span class="math inline">\(\mathcal{D}\)</span> is not convex (reasons for this are beyond
the scope of this class but interested readers can verify this independently without
too much difficulty). This is the reason why we couldn’t find <span class="math inline">\(k\)</span> and <span class="math inline">\(C\)</span> in Example
<a href="neyman-pearson-lemma.html#exm:critical-region">4.2</a> if <span class="math inline">\(\alpha=1/1000\)</span>.</p>
<p>As a fix to this problem, one seeks to convexify the set <span class="math inline">\(\mathcal{D}\)</span>,
which turns out to be the set
<span class="math inline">\(\mathcal{H} = \{\varphi \, | \, 0\leq \varphi \leq 1 \}\)</span>.</p>
<div class="definition">
<p><span id="def:unlabeled-div-119" class="definition"><strong>Definition 4.6  </strong></span>A <em>randomized critcal function</em> <span class="math inline">\(\varphi\)</span> is a function such that
<span class="math display">\[ 0 \leq \varphi \leq 1. \]</span></p>
<p>The <em>power</em> of the randomized critical function <span class="math inline">\(\varphi\)</span> for a paremeter <span class="math inline">\(\theta_1 \in D_1\)</span> is
<span class="math display">\[\beta_{\theta_1}(\varphi) = \mathbb{E}_{\theta_1} \varphi(X).\]</span></p>
<p>The <em>size</em> of a randomized critical function <span class="math inline">\(\varphi\)</span> is
<span class="math display">\[ \sup_{\theta_0 \in D_0} \mathbb{E}_{\theta_0} \varphi(X).\]</span></p>
</div>
<p>Note that, in this setting, critical regions only correspond to non-randomized
critical functions.
In the randomized setting, critical regions become less relevant.
What’s important is what kind of critical function are we using to make decision.
However, there’s an an intepretation of the randomized critical function
in terms of critical region, if we are willing to take into consideration a decision process
that is completely random and independent with what we are testing (hence the term randomized critical function). This process is captured by the following exercise:</p>
<div class="exercise">
<p><span id="exr:unlabeled-div-120" class="exercise"><strong>Exercise 4.5  (Keener, 12.8.1) </strong></span>Suppose <span class="math inline">\(X \sim P_\theta\)</span> for some <span class="math inline">\(\theta \in \Omega\)</span>, and that <span class="math inline">\(U\)</span>
is uniformly distributed on <span class="math inline">\((0,1)\)</span> and is independent of <span class="math inline">\(X\)</span>.
Let <span class="math inline">\(\phi(X)\)</span> be a test based on <span class="math inline">\(X\)</span>.
Find a nonrandomized test based on <span class="math inline">\(X\)</span> and <span class="math inline">\(U\)</span>, so <span class="math inline">\(\psi(X, U) = \chi_S(X, U)\)</span>
for some critical region <span class="math inline">\(S\)</span>, with the same power function
as <span class="math inline">\(\phi\)</span>, <span class="math inline">\(E_\theta\phi(X) = E_\theta\psi(X, U)\)</span>, for all <span class="math inline">\(\theta \in \Omega\)</span>.</p>
</div>
<p>With this new technical tool, Neyman-Pearson theorem is cloaked in a new, more powerful coat.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-121" class="theorem"><strong>Theorem 4.2  </strong></span>Let <span class="math inline">\(X_1, \dots, X_n\)</span> be a sample from a family of distributions <span class="math inline">\(f(x;\theta)\)</span>,
where <span class="math inline">\(\theta \in \{\theta_0, \theta_1\}\)</span>.
There exist <span class="math inline">\(k\)</span> is a positive number and a randomized critical function <span class="math inline">\(\varphi\)</span> such that</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\displaystyle{\frac{\mathcal{L}(\theta_0;x)}{\mathcal{L}(\theta_1;x)}} &lt; k\)</span> when <span class="math inline">\(\varphi(x) = 1\)</span>.</li>
<li><span class="math inline">\(\displaystyle\frac{\mathcal{L}(\theta_0;x)}{\mathcal{L}(\theta_1;x)} &gt; k\)</span> when <span class="math inline">\(\varphi(x) = 0\)</span>.</li>
<li><span class="math inline">\(\alpha = E_{\theta_0}\varphi(X)\)</span>.</li>
</ol>
<p><span class="math inline">\(\varphi\)</span> is a best randomized critical function of size <span class="math inline">\(\alpha\)</span> for testing the hypothesis
<span class="math inline">\(H_0: \theta= \theta_0\)</span> against the alternative hypothesis <span class="math inline">\(H_1: \theta = \theta_1\)</span>. That is, among all the critical functions of size <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(varphi\)</span> has the biggest power.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-122" class="proof"><em>Proof</em>. </span>See <span class="citation">(<a href="#ref-lehmann2005testing">Lehmann and Romano 2005</a>, Theorem 3.2.1)</span>.</p>
</div>
<p>Finally, it could be proved that the best randomized test given by the Neyman-Pearson theorem
is unbiased.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-123" class="proposition"><strong>Proposition 4.1  </strong></span>Let <span class="math inline">\(\varphi\)</span> be the best randomized critical function of size <span class="math inline">\(\alpha\)</span> of <span class="math inline">\(H_0: \theta = \theta_0\)</span>
versus <span class="math inline">\(H_1: \theta = \theta_1\)</span>.
Then
<span class="math display">\[\beta_{\theta_1}(\varphi) \geq \alpha.\]</span>
Furthermore,
the equality is achieved if and only if <span class="math inline">\(\theta_1 = \theta_0\)</span>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-124" class="proof"><em>Proof</em>. </span>See <span class="citation">(<a href="#ref-lehmann2005testing">Lehmann and Romano 2005</a>, Corollary 3.2.1)</span>.</p>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-keener2010theoretical" class="csl-entry">
Keener, Robert W. 2010. <em>Theoretical Statistics: Topics for a Core Course</em>. New York: Springer.
</div>
<div id="ref-lehmann2005testing" class="csl-entry">
Lehmann, Erich L., and Joseph P. Romano. 2005. <em>Testing Statistical Hypotheses</em>. 3rd ed. New York: Springer.
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-119" class="exercise"><strong>Exercise 4.4  (Hogg et. al., 8.1.5) </strong></span>If <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> is a random sample from a distribution having pdf of the form <span class="math inline">\(f(x ; \theta)=\theta x^{\theta-1}, 0&lt;x&lt;1\)</span>, zero elsewhere, show that a best critical region for testing <span class="math inline">\(H_0: \theta=1\)</span> against <span class="math inline">\(H_1: \theta=2\)</span> is <span class="math inline">\(C=\left\{\left(x_1, x_2, \ldots, x_n\right): c \leq \prod_{i=1}^n x_i\right\}\)</span>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="procedure.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="uniformly-most-powerful-test.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MathStat.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
