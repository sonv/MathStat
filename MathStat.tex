% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  openany]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={MATH 310: Mathematical Statistics (brief notes)},
  pdfauthor={Truong-Son Van},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{MATH 310: Mathematical Statistics (brief notes)}
\author{Truong-Son Van}
\date{}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\chapter*{Disclaimer}\label{disclaimer}


This is class notes for Mathematical Statistics at Fublbright University Vietnam.
I claim no originality in this work as it is mostly taken from the reference books.
However, all errors and typos are solely mine.

\newcommand{\vectorproj}[2][]{\mathrm{proj}_{\vect{#1}}\vect{#2}}
\newcommand{\vectorcomp}[2][]{\mathrm{comp}_{\vect{#1}}\vect{#2}}
\newcommand{\vect}{\mathbf}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\eqd}{\stackrel{d}{=}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cB}{\mathcal{B}}
\newtheorem{question}{Question}

\newpage

\chapter*{PART 1: Background}\label{part-1-background}


\chapter{Probability}\label{probability}

\begin{quote}
``If we have an atom that is in an excited state and so is going to emit a photon, we cannot say when it will emit the photon. It has a certain amplitude to emit the photon at any time, and we can predict only a probability for emission; we cannot predict the future exactly.''

\hfill --- Richard Feynman
\end{quote}

\section{Review}\label{review}

\subsection{Probability Space}\label{probability-space}

\begin{definition}[Sigma-algebra]

Let \(\Omega\) be a set.
A set \(\Sigma \subseteq \mathcal{P}(\Omega)\) of subsets of \(\Omega\) is called a \(\sigma\)-algebra
of \(\Omega\) if

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\Omega\in \Sigma\)
\item
  \(F \in \Sigma \implies F^C \in \Sigma\)
\item
  If \(F_n \in \Sigma\) for all \(n\in \mathbb{N}\), then
  \[ \bigcup_n F_n \in \Sigma .\]
\end{enumerate}

\end{definition}

It is extremely convenient to deal with things called open sets.
The definition of those are a bit out of the scope of this class.
However,
in the case of the real line \(\mathbb{R}\), open sets are defined to be made of by finite intersections and arbitrary unions of open intervals \((a,b)\).
For example, \((0,1)\cup (2,3)\) is an open set.

Interestingly, \(\mathbb{R}\) and \(\emptyset\) are called clopen sets (here's a funny YouTube video about clopen sets: \url{https://www.youtube.com/watch?v=SyD4p8_y8Kw})

A Borel \(\sigma\)-algebra is the smallest \(\sigma\)-algebra that contains all the open sets.
We denote the Borel \(\sigma\)-algebra of a set \(\Omega\) to be \(\mathcal{B}(\Omega)\).
This is a rather abstract definition. There is no clear way to construct a sigma algebra from a collection of sets. However, the construction is not important as the reassurance that this object does exist to give us nice domains to work with when we define a probability measure (see below definition).

\begin{exercise}
(\emph{Challenging-- not required but good for the brain})
It turns out that if \(\Omega\) is a discrete set, it is typical to have the set of open sets contain every set of singletons, i.e.,
the set \(\{ a \}\) is open for every \(a\in \Omega\).
Take this as an assumption, show that
for any discrete set \(\Omega\), \(\mathcal{B}(\Omega) = \mathcal{P}(\Omega)\).
\end{exercise}

What open sets really are is not important for now. The important thing is that for \(\mathbb{R}^n\)
open sets are made of open intervals/ open boxes.
Your typical intuitions still work.

Philosophically, the \(\sigma\)-algebra represents the details of information we could have access to.
There are certain events that are building blocks of knowledge and that we don't have
access to finer details.

Think about the \(\sigma\)-algebra as a consistent model of what can be known (observed). For example, you can never know
what's going on in the houses on the street unless you have been to them.
But somehow, together, you are still able to piece all the information you have about the houses
to make sense of the world. This is related to the problem of information. How much information is enough to be useful in certain situation?!

To have a consistent system is not the same as to know everything. The system
you see/invent can never be exhaustively true, but you can still say something about
the reality if you can have a system that is consistent with what you observe. This
is why we do sampling!!

When you have a consistent model, you now want to encode the model in such a way
that it helps you with describing/predict the reality you see.
A way to do that with no full knowledge of anything is to assign the certain number
to measure the chance for something to happen at a given time.
This encoding needs to happen on the model you constructed. This leads to the following definition of
probability space.

\begin{definition}[Probability Space]
A \emph{Probability Space} is a triple \((\Omega, \mathcal{F}, \mathbb{P})\), where
\(\Omega\) is a set called \emph{sample space}, \(\mathcal{F}\) is a \(\sigma\)-algebra on \(\Omega\),
\(\mathbb{P}: \mathcal{F}\to [0,1]\), called a \emph{Probability Measure}, is a function that satisfies the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\mathbb{P}(\Omega) =1\),
\item
  If \(F\) is a disjoint union of \(\left\{ F_n \right\}_{n=1}^\infty\), then
  \[ \mathbb{P}(F) = \sum_{n=1}^\infty \mathbb{P}(F_n) . \]
\end{enumerate}

Each element \(\omega \in \Omega\) is called an \emph{outcome} and each subset \(A \in \mathcal{F}\)
is called an \emph{event}.
\end{definition}

\begin{definition}[Independent Events]
Let \(A, B \in \mathcal{F}\) be events. We say that \(A\) and \(B\) are independent
if
\[ \mathbb{P}(A \cap B) = \mathbb{P}(A) \mathbb{P}(B)  \,. \]
\end{definition}

\begin{definition}[Conditional Probability]
Let \(A, B \in \mathcal{F}\) be events such that \(\mathbb{P}(B) >0\). Then, the conditional probability of
\(A\) given \(B\) is
\[ \mathbb{P}(A \vert B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)} \,. \]
\end{definition}

\begin{theorem}[Bayes's Theorem]
Let \(A, B \in \mathcal{F}\) be events such that \(\mathbb{P}(A)>0\) and \(\mathbb{P}(B) >0\).
Then,
\[\mathbb{P}(A | B) = \frac{\mathbb{P}(B | A) \mathbb{P}(A)}{\mathbb{P}(B)} \,.\]
\end{theorem}

In modern statistics, there are names for the above terms:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\mathbb{P}(A | B)\) is called \emph{Posterior Probability},
\item
  \(\mathbb{P}(B | A)\) is called \emph{Likelihood},
\item
  \(\mathbb{P}(A)\) is called \emph{Prior Probability},
\item
  \(\mathbb{P}(B)\) is called \emph{Evidence}.
\end{enumerate}

The theorem is often expressed in words as:

\[ \text{Posterior Probability} = \frac{\text{Likelihood} \times \text{Prior Probability}}{\text{Evidence}} \]

It is a good idea to ponder why those mathematical terms have those names.

\subsection{Random Variables}\label{random-variables}

The notion of probability alone isn't sufficient for us to describe ideas about the world.
We need to have a notion of objects that associated with probabilities.
This brings about the idea of \emph{random variable}.

\begin{definition}[Random Variable]

Let \((\Omega, \mathcal{B}(\Omega), \mathbb{P})\) be a probability space and \((S, \mathcal{B}(S))\) a \(\sigma\)-algebra.
A random variable is a (Borel measurable) function from \(\Omega \to S\).

\begin{itemize}
\tightlist
\item
  \(S\) is called the \emph{state space} of \(X\).
\end{itemize}

\end{definition}

In this course, we will restrict our attentions to two types of random variables: discrete and continuous.

\begin{definition}[Discrete RV]

\(X: \Omega \to S\) is called
a discrete RV if \(S\) is a countable set.

\begin{itemize}
\tightlist
\item
  A \emph{probability function} or \emph{probability mass function} for \(X\) is a function
  \(f_X: S \to [0,1]\) defined by
  \[ f_X(x) = \mathbb{P}(X = x) \,. \]
\end{itemize}

\end{definition}

In contrast to the simplicity of discrete RV. Continuous RVs are a little bit messier to describe.
This is because of the lack of background in measure theory so we can talk about this concept in
a more precise way.

\begin{definition}[Continuous RV]
A \emph{continuous random variable} is a measurable function \(X:\Omega \to S\) is continuous
if it satisfies the following conditions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(S = \mathbb{R}^n\) for some \(n\in \mathbb{N}\).
\item
  There exists an (integrable) function \(f_X\) such that \(f_X(x) \geq 0\)
  for all \(x, \int_{\mathbb{R}^n} f_X(x) d x=1\) and for every open cube \(C \subseteq \mathbb{R}^n\),
  \[
  \mathbb{P}(X\in C)=\int_C f_X(x) dV .
  \]
\end{enumerate}

The function \(f_X\) is called the \emph{probability density function (PDF)}.
\end{definition}

If two RVs \(X\) and \(Y\) share the same probability function, we say that they
have the same distribution and denote them by
\[ X \stackrel{d}{=}Y.\]

In this case we also say that \(X\) and \(Y\) are \textbf{equal in distribution}.

\begin{remark}
To make the presentation more compact and clean,
notationally, we will write
\[ \int f(x)  dx \]
to mean both integral (for continuous RV) and summation (for discrete RV).
\end{remark}

There are more general concepts of continuous RV where we don't need to require
\(S\) to be a Euclidean space as in the above definition.
However, such concepts require the readers to be familiar with advanced subjects
like Topology and Measure Theory. It is particularly important to know these two
subjects
in order to thoroughly understand Stochastic Processes.

\begin{exercise}
Create a random variable that represents the results of \(n\) coin flips.
\end{exercise}

For real-valued RV \(X:\Omega \to \mathbb{R}\) we have the concept of cumulative distribution function.

\begin{definition}[Cumulative Distribution Function]
Given a RV \(X:\Omega \to \mathbb{R}\).
The \emph{cumulative distribution function of \(X\)} or CDF, is
a function \(F_X : \mathbb{R}\to [0,1]\)
defined by
\[ F_X (x) = \mathbb{P}(X \leq x) \,. \]
\end{definition}

\textbf{Notationally, we use the notation \(X\sim F\) to mean
RV \(X\) with distribution \(F\).}

\begin{exercise}
Given a real-valued continuous RV \(X: \Omega \to \mathbb{R}\), prove that
if \(f_X\) is continuous then
\[
F_X(x)=\int_{-\infty}^x f_X(t) d t
\]
is differentiable for every \(x\)
and \(f_X(x)=F_X^{\prime}(x)\).
\end{exercise}

\begin{exercise}
Let \(X\) be an RV with CDF \(F\) and \(Y\) with CDF \(G\).
Suppose \(F(x) = G(x)\) for all \(x\). Show that for every set \(A\) that
is a countable union of open intervals,
\[ \mathbb{P}(X \in A) = \mathbb{P}(Y \in A) \,.\]
\end{exercise}

\begin{exercise}

Let \(X:\Omega \to \mathbb{R}\) be an RV and \(F_X\) be its CDF.
Prove the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(F\) is non-decreasing: if \(x_1 \leq x_2\), then \(F(x_1) \leq F(x_2)\).
\item
  \(F\) is normalized:
  \[ \lim_{x\to -\infty} F(x) = 0 \,,\]
  and
  \[ \lim_{x\to \infty} F(x) = 1 \,.\]
\item
  \(F\) is right-continuous:
  \[ F(x) = F(x+) = \lim_{y \searrow x} F(y) \,.\]
\end{enumerate}

\end{exercise}

\subsection{Joint distribution of RVs}\label{joint-distribution-of-rvs}

Let \(X:\Omega \to S\) and \(Y: \Omega \to S\) be RVs.
We denote
\[ \mathbb{P}(X \in A; Y \in B) = \mathbb{P}(\{X\in A\} \cap \{Y \in B \}) \,. \]

For discrete RVs, the joint probability function of \(X\) and \(Y\) has the following meaning
\[f_{XY}(x,y) = \mathbb{P}(X = x; Y = y)\]

For continuous RVs, the situations are more complicated as we can't make sense of \(\mathbb{P}(X = x; Y = y)\) (this is always 0 in most situation and in some other situation, one can't even talk about it-- this is a topic of more advanced course in measure theory).
However, we can have
\[\mathbb{P}(X \in A; Y \in B) = \int_{X \in A} \int_{Y \in B} f_{XY} (x,y) \, dx dy \,.\]

Another way to look at the above is the following.
We can even consider
\(X: \Omega \to S^n\),
where \(n\geq 2\).
Instead of thinking about this as one RV, we can think about this
as a vector of RVs:
\[ X = \begin{pmatrix} X_1 \\ \vdots \\ X_n \end{pmatrix},\]
where \(X_1, \dots X_n: \Omega \to S\) are RVs.
Because of this, we have can write the density function as
\[ f_X(x) = f_{X_1 X_2 \dots X_n}(x)\]

Some people call \(X\) a random vector.

\(f_{X_1\dots X_n}\) is called the joint probability distribution.

\begin{exercise}

True or false:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(f_{XY}(x,y) = f_{X}(x) + f_{Y}(y)\)
\item
  \(f_{XY}(x,y) = f_{X}(x) f_{Y}(y)\)
\end{enumerate}

\end{exercise}

\begin{definition}[Marginal density]
The marginal density of \(X_i\) is
\[f_{X_i}(x_i) = \int f_{X_1\dots X_n}(x_1, \dots, x_n) \, dx_1\dots dx_{i-1} dx_{i+1} \dots dx_n\]
(integrate coordinate except the \(i\)-th coordinate.
\end{definition}

\begin{exercise}
Can you construct \(f_{XY}\) if you know \(f_X\) and \(f_Y\)?
\end{exercise}

\subsection{Some important random variables}\label{some-important-random-variables}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Point mass distribution (Dirac delta):
  Given a discrete probability \(X: \Omega \to S\). \(X\) has a point mass distribution at \(a \in S\)
  if
  \[ \mathbb{P}( X = a) = 1.\]
  We call \(X\) a point mass RV and write \(X \sim \delta_a\).

  \emph{Question.} Suppose \(S = \mathbb{N}\). Write down \(F_X\) for the point mass RV \(X\).
\item
  Discrete uniform distribution:
  \(f_X(k) = \frac 1 n\,,\)
  \(k \in \{1,\dots, n\}\).
\item
  Bernoulli distribution:
  let \(X:\Omega \to \{0,1\}\) be RV that represents a binary coin flip.
  Suppose \(\mathbb{P}(X = 1) = p\) for some \(p \in [0,1]\).
  Then \(X\) has a Bernoulli distribution, written as \(X \sim \text{Bernoulli}(p)\).
  The probability function is
  \[f_X(x) = p^x (1-p)^{1-x}.\]
  We write \(X \sim \text{Bernoulli}(p)\).
\item
  Binomial distribution:
  let \(X:\Omega \to \mathbb{N}\) be the RV that represents the number of heads out of \(n\) independent coin flips.
  Then
  \[ f_X = \begin{cases}
  {n \choose x} p^x (1-p)^{n-x}\,, x\in \{0,1,\dots, n\}\\
       0 \,, \text{otherwise}
  \end{cases}\]
  We write \(X \sim \text{Binomial}(n,p)\).
\item
  Poisson distribution: \(X \sim \text{Poisson}(\lambda)\).
  \[f_X (x) = e^{-\lambda} \frac{\lambda^x}{x!}\,, x \geq 0.\]
  \(X\) is a RV that describe a given number of events occurring in a
  fixed interval of time or space if these events occur with a known constant mean rate and
  independently of the time since the last event
\item
  Gaussian: \(X \sim N(\sigma,\mu)\).
  \[f_X(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-(x-\mu)^2/(2\sigma^2)}.\]
\end{enumerate}

\begin{exercise}

Let \(X_{n,p} \sim \text{Binomial}(n,p)\). Suppose that as \(n\to \infty\), \(p \to 0\) in such a way
that \(np = \lambda\) always.
Let \(x\in \mathbb{N}\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  For \(n\) very very large, what is the behaviour of\\
  \[ \frac{n!}{(n-x)!} \,.\]
  (You should just get some power of \(n\))
\item
  Show that
  \[\lim_{n\to \infty} f_{X_{n,p}}(x) = \frac{\lambda^x e^{-\lambda}}{x!}.\]
\item
  Interpret this result.
\end{enumerate}

\end{exercise}

\subsection{Independent random variables}\label{independent-random-variables}

\begin{definition}
Let \(X:\Omega \to S\) and \(Y: \Omega \to S\) be RVs.
We say that \(X\) and \(Y\) are independent if,
for every \(A, B \in \mathcal{B}(S)\), we have
\[ \mathbb{P}( X \in A; Y \in B) = \mathbb{P}(X \in A) \mathbb{P}(Y \in B) \,, \]
and write \(X \perp Y\).
\end{definition}

So, if \(X\) and \(Y\) are independent,
\[f_{XY}(x,y) = f_X(x) f_Y(y).\]

\begin{definition}
Let \(X:\Omega \to S\) and \(Y: \Omega \to S\) be RVs.
Suppose that \(f_Y(y) >0\).
The conditional probability mass function of \(X\) given \(Y\) is
\[ f_{X|Y} (x|y) = \frac{f_{XY}(x,y)}{f_Y(y)} \,.\]
\end{definition}

\begin{exercise}
Let
\[ f(x,y) = \begin{cases} x+y \,, 0\leq x \leq 1, 0 \leq y \leq 1\\
            0\,, \text{otherwise} \end{cases}.\]
What is \(\mathbb{P}( X < 1/4 \vert Y = 1/3)\).
\end{exercise}

Note that the above exercise is a little bit weird and counter-intuitive.
While
\(\mathbb{P}( X < 1/4 , Y = 1/3) = 0\) (why?),
\(\mathbb{P}( X < 1/4 | Y = 1/3) \not= 0\)

A very important RV is the \emph{multivariate Normal RV}, which obeys the
following density function

\[f(x; \mu, \Sigma) = \frac{1}{(2\pi)^{n/2} | \Sigma |^{1/2}} \exp\big( -\frac{1}{2} (x-mu)^T \Sigma^{-1} (x-\mu)  \big).\]

\subsection{Transformations of RVs}\label{transformations-of-rvs}

Sometimes, we don't work with RV directly but certain characteristics of RVs.
Those characteristics are represented by certain transformation.
If the functions are nice enough, we can actually have a recipe to generate
the probability density function.

Suppose \(g: S^n \to \mathbb{R}\) and \(Z = g(X_1, \dots, X_n)\).
Let \(A_z = \{ (x_1,\dots, x_n): g(x_1,\dots, x_n) \leq z \}\).
Then
\[F_Z(z) = \mathbb{P}(Z \leq z) = \mathbb{P}(g(X_1, \dots, X_n) \leq z) = \int_{A_z} f_{X_1\dots X_n}(x_1,\dots,x_n) \, dx_1\dots dx_n, \]
and
\[f_Z(z) = F_Z'(z).\]

\begin{exercise}
\leavevmode

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Let \(X, Y \sim \text{Uniform}(0,1)\) be independent RVs, i.e.,
  \[f_{X}(x) = f_{Y}(y) = 1\,.\]
  What is the density function for the RV \(Z = X + Y\)?
\item
  Same question but \(X, Y \sim N(0,1)\).
\end{enumerate}

\end{exercise}

\begin{definition}
RVs that are independent and share the same distribution are called
\emph{independent and identically distributed} RVs.

We often shorthand this by IID RVs.
\end{definition}

\subsection{Expectation}\label{expectation}

\begin{definition}
Let \(X\) be a RV.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The \emph{expected value}, or \emph{expectation}, or \emph{mean}, or \emph{first moment} of \(X\) is defined to be
  \[ \mathbb{E}X = \int x f(x)  dx. \]
\item
  The \emph{variance} of \(X\) is defined to be
  \[\mathbb{E}\left( X - \mathbb{E}X \right)^2\]
\end{enumerate}

We often denote \(\mu_X\) to be the expectation of \(X\), \(\sigma_X^2\) (\(\mathrm{Var}(X), \mathbb{V}(X)\)) to be the variance of \(X\).

The square root of the variance, \(\sigma\), is called the \emph{standard deviation}.
\end{definition}

\begin{theorem}
Let \(X:\Omega \to S\) be a RV, \(r: S \to S\) be a function and \(Y = r(X)\).
Then \[ \mathbb{E}Y = \mathbb{E}(r(X)) = \int r(x) f(x)  dx \]
\end{theorem}

\begin{exercise}
\leavevmode

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Let \(X \sim \text{Uniform}(0,1)\). Compute \(\mathbb{E}Y\), where

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    \(Y = e^X\).
  \item
    \(Y = \max(X, 1-X)\)
  \end{enumerate}
\item
  Let \(X,Y\) be RVs that have jointly uniform distribution on the unit square.
  Compute \(\mathbb{E}(X^2 + Y^2)\).
\end{enumerate}

\end{exercise}

\begin{definition}
Let \(X\) and \(Y\) be RVs. The \emph{covariance} between \(X\) and \(Y\) is defined by
\[ \mathrm{Cov}(X,Y) = \mathbb{E}\left( (X- \mu_X)(Y - \mu_Y)   \right) .\]

The \emph{correlation} of \(X\) and \(Y\) is defined to be
\[ \rho_{X,Y} = \frac{\mathrm{Cov}(X,Y)}{\sigma_X \sigma_Y} \,.\]
\end{definition}

\begin{theorem}
\leavevmode

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Let \(X_i\), \(i=1, \dots, n\) be RVs and \(a_i\)'s be constants.
  Then
  \[ \mathbb{E}\left(\sum_i a_i X_i \right) = \sum_i a_i \mathbb{E}X_i. \]
\item
  \[ \mathbb{V}X_i = \mathbb{E}(X_i^2) - \mu_{X_i}^2 \]
\item
  \[ \mathbb{V}\left( \sum_i a_i X_i  \right) = \sum_i a_i^2 \mathbb{V}(X_i) \]
\item
  \[ \mathbb{V}\left( \sum_i a_i X_i  \right) = \sum_i a_i^2 \mathbb{V}(X_i) + 2\sum_{i<j} a_i a_j \mathrm{Cov}(X_i, X_j) \,. \]
\item
  Suppose further that \(X_i\)'s are independent, then
  \[ \mathbb{E}\left( \prod_{i=1}^n X_i  \right) = \prod_{i=1}^n \mathbb{E}X_i\]
  and
  \[ \mathbb{V}\left( \sum_i a_i X_i  \right) = \sum_i a_i^2 \mathbb{V}(X_i) \,. \]
\end{enumerate}

\end{theorem}

\begin{definition}[Conditional Expectation]
Let \(X,Y:\Omega \to S\), where \(S\) is either \(\mathbb{N}\) or \(\mathbb{R}\).
The conditional expectation of \(X\) given \(Y\) is a RV \(\mathbb{E}[X | Y] : \Omega \to \mathbb{R}\)
that satisfies the following
\[ \mathbb{E}[X | Y](y) := \mathbb{E}[X | Y = y] = \int x f_{X|Y}(x|y) \, dx . \]
If \(r:S^2 \to S\) is a function, then
\[ \mathbb{E}[r(X,Y) | Y = y] = \int r(x,y) f_{X|Y}(x|y) \, dx .\]
\end{definition}

One can generalize this definition to higher dimension via the coordinate-wise conditional
expectation. We will omit this definition in order to keep the presentation simple.

\begin{theorem}
Let \(X\) and \(Y\) be Rvs. We have that
\[ \mathbb{E}[ \mathbb{E}[X | Y]] = \mathbb{E}X. \]
\end{theorem}

\subsection{Moment Generating and Characteristics Functions}\label{moment-generating-and-characteristics-functions}

\begin{definition}

Let \(X\) be a RV.
1. The \emph{moment generating function} MGF, or \emph{Laplace transform}, of \(X\) is \(\varphi: \mathbb{R}\to \mathbb{R}\) defined by
\[ \varphi_X (t) = \mathbb{E}\left( e^{t X}  \right),  \]
where \(t\) varies over the real numbers.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The \emph{characteristics function}, or \emph{Fourier transform} of \(X\) is \(\varphi: \mathbb{R}\to \mathbb{C}\) defined by
  \[\phi_X(\theta) = \mathbb{E}e^{i\theta X} .\]
\end{enumerate}

\end{definition}

\begin{lemma}
\leavevmode

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Let \(X\) be a RV and \(Y = aX + b\), then
  \[ \varphi_Y(t) = e^{bt} \varphi_{X}(at)\]
\item
  \[ \varphi_X^{(k)}(0) = \mathbb{E}(X^k) \]
\item
  Let \(X_i\), \(i= 1, \dots, n\) be independent RVs and \(Y = \sum_i X_i\).
  Then
  \[ \varphi_Y (t) = \prod \varphi_{X_i}(t). \]
\item
  \[| \phi (\theta) | \leq 1\]
\item
  Denote \(\overline{z}\) to be the complex conjugate of \(z\) in the complex plane.
  \[ \phi_{-X} (\theta) = \overline{\phi_X (\theta)} \]
\item
  \[\phi_Y (\theta) = e^{i b \theta} \phi(a\theta) \]
\end{enumerate}

\end{lemma}

\begin{exercise}
Prove the above lemma.
\end{exercise}

\begin{exercise}
Let \(X \sim \exp(1)\), i.e,
\[ f_X(x) = \begin{cases} e^{-x} \,, x \geq 0 \\ 0 \,, x < 0 \,. \end{cases}\]
Compute \(\varphi_X\).
\end{exercise}

Recall that two RVs \(X \stackrel{d}{=}Y\) means that \(F_X (x) = F_Y(x)\).
Two common ways to characterize the equality in distribution are
to use the generating functions and the characteristic functions.

These ideas are not orginally from probability but from engineering/mechanics, where Laplace and Fourier transforms are understood very well
since the 18th century.

\begin{theorem}
Let \(X\) and \(Y\) be RVs. If \(\varphi_X(t) = \varphi_Y(t)\) for all \(t\) in an interval around 0, then
\[ X  \stackrel{d}{=}Y \,.\]
\end{theorem}

The full proof of this is beyond this class (and could be a great topic for a project).
However, we will prove this for discrete RVs.

\begin{proposition}[Discrete RV case]
Let \(X,Y: \Omega \to \mathbb{N}\) be discrete RVs. If \(\varphi_X(t) = \varphi_Y(t)\) for all \(t\) in an interval around 0, then
\[ X  \stackrel{d}{=}Y \,.\]
\end{proposition}

\begin{proof}
(to be written)
\end{proof}

We have a similar statement for characteristics function. However, the proof of this is a little more manageable.

\begin{theorem}
Let \(X\) and \(Y\) be RVs. If \(\phi_X(t) = \phi_Y(t)\) for all \(t\) in an interval around 0, then
\[ X  \stackrel{d}{=}Y \,.\]
\end{theorem}

\begin{proof}
to be written
\end{proof}

\section{Inequalities}\label{inequalities}

\section{Law of Large Numbers}\label{law-of-large-numbers}

\section{Central Limit Theorem}\label{central-limit-theorem}

\chapter*{PART 2: Inference}\label{part-2-inference}


\chapter{Sampling, Estimating CDF and Statistical Functionals}\label{sampling-estimating-cdf-and-statistical-functionals}

\section{Empirical Distribution}\label{empirical-distribution}

\section{Statistical Functionals}\label{statistical-functionals}

\section{Bootstrap}\label{bootstrap}

\chapter{Parametric Inference (Parameter Estimation)}\label{parametric-inference-parameter-estimation}

\section{Method of Moments}\label{method-of-moments}

\section{Method of Maximum Likelihood}\label{method-of-maximum-likelihood}

\section{Bayesian Approach}\label{bayesian-approach}

\section{Expectation-Maximization Algorithm}\label{expectation-maximization-algorithm}

\section{Unbiased Estimators}\label{unbiased-estimators}

\section{Efficiency: Cramer-Rao Inequality}\label{efficiency-cramer-rao-inequality}

\section{Sufficiency and Unbiasedness: Rao-Blackwell Theorem}\label{sufficiency-and-unbiasedness-rao-blackwell-theorem}

\chapter{Hypothesis Testing}\label{hypothesis-testing}

\section{Neyman-Pearson Lemma}\label{neyman-pearson-lemma}

\section{Wald Test}\label{wald-test}

\section{Likelihood Ratio Test}\label{likelihood-ratio-test}

\section{Comparing samples}\label{comparing-samples}

\chapter*{PART 3: Models}\label{part-3-models}


\chapter{Linear Least Squares}\label{linear-least-squares}

\section{Simple Linear Regression}\label{simple-linear-regression}

\section{Matrix Approach}\label{matrix-approach}

\section{Statistical Properties}\label{statistical-properties}

\end{document}
