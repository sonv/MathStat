<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.3 Constructing estimators | MATH 310: Mathematical Statistics (brief notes)</title>
  <meta name="description" content="2.3 Constructing estimators | MATH 310: Mathematical Statistics (brief notes)" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="2.3 Constructing estimators | MATH 310: Mathematical Statistics (brief notes)" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.3 Constructing estimators | MATH 310: Mathematical Statistics (brief notes)" />
  
  
  

<meta name="author" content="Truong-Son Van" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="statistical-estimation.html"/>
<link rel="next" href="empirical-distribution.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a>Mathematical Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Disclaimer</a></li>
<li class="chapter" data-level="" data-path="syllabus.html"><a href="syllabus.html"><i class="fa fa-check"></i>Syllabus</a>
<ul>
<li class="chapter" data-level="" data-path="syllabus.html"><a href="syllabus.html#key-information"><i class="fa fa-check"></i>Key information</a></li>
<li class="chapter" data-level="" data-path="textbooks-and-references.html"><a href="textbooks-and-references.html"><i class="fa fa-check"></i>Textbooks and references</a>
<ul>
<li class="chapter" data-level="" data-path="textbooks-and-references.html"><a href="textbooks-and-references.html#course-description"><i class="fa fa-check"></i>Course description</a></li>
<li class="chapter" data-level="" data-path="textbooks-and-references.html"><a href="textbooks-and-references.html#learning-objectives"><i class="fa fa-check"></i>Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="assessment.html"><a href="assessment.html"><i class="fa fa-check"></i>Assessment</a></li>
<li class="chapter" data-level="" data-path="core-content.html"><a href="core-content.html"><i class="fa fa-check"></i>Core content</a></li>
<li class="chapter" data-level="" data-path="project-description.html"><a href="project-description.html"><i class="fa fa-check"></i>Project description</a>
<ul>
<li class="chapter" data-level="" data-path="project-description.html"><a href="project-description.html#topics"><i class="fa fa-check"></i>Topics</a></li>
<li class="chapter" data-level="" data-path="project-description.html"><a href="project-description.html#deadlines"><i class="fa fa-check"></i>Deadlines</a></li>
<li class="chapter" data-level="" data-path="project-description.html"><a href="project-description.html#project-guidelines"><i class="fa fa-check"></i>Project Guidelines</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="late-assignments.html"><a href="late-assignments.html"><i class="fa fa-check"></i>Late assignments</a></li>
<li class="chapter" data-level="" data-path="time-expectations.html"><a href="time-expectations.html"><i class="fa fa-check"></i>Time expectations</a>
<ul>
<li class="chapter" data-level="" data-path="time-expectations.html"><a href="time-expectations.html#collaboration-plagiarism"><i class="fa fa-check"></i>Collaboration &amp; Plagiarism</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="learning-support.html"><a href="learning-support.html"><i class="fa fa-check"></i>Learning Support</a></li>
<li class="chapter" data-level="" data-path="wellbeing.html"><a href="wellbeing.html"><i class="fa fa-check"></i>Wellbeing</a></li>
<li class="chapter" data-level="" data-path="tentative-course-schedule.html"><a href="tentative-course-schedule.html"><i class="fa fa-check"></i>Tentative Course Schedule</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-1-background.html"><a href="part-1-background.html"><i class="fa fa-check"></i>PART 1: Background</a></li>
<li class="chapter" data-level="1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>1</b> Probability</a>
<ul>
<li class="chapter" data-level="1.1" data-path="review.html"><a href="review.html"><i class="fa fa-check"></i><b>1.1</b> Review</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="review.html"><a href="review.html#probability-space"><i class="fa fa-check"></i><b>1.1.1</b> Probability Space</a></li>
<li class="chapter" data-level="1.1.2" data-path="review.html"><a href="review.html#random-variables"><i class="fa fa-check"></i><b>1.1.2</b> Random Variables</a></li>
<li class="chapter" data-level="1.1.3" data-path="review.html"><a href="review.html#joint-distribution-of-rvs"><i class="fa fa-check"></i><b>1.1.3</b> Joint distribution of RVs</a></li>
<li class="chapter" data-level="1.1.4" data-path="review.html"><a href="review.html#some-important-random-variables"><i class="fa fa-check"></i><b>1.1.4</b> Some important random variables</a></li>
<li class="chapter" data-level="1.1.5" data-path="review.html"><a href="review.html#independent-random-variables"><i class="fa fa-check"></i><b>1.1.5</b> Independent random variables</a></li>
<li class="chapter" data-level="1.1.6" data-path="review.html"><a href="review.html#transformations-of-rvs"><i class="fa fa-check"></i><b>1.1.6</b> Transformations of RVs</a></li>
<li class="chapter" data-level="1.1.7" data-path="review.html"><a href="review.html#expectation"><i class="fa fa-check"></i><b>1.1.7</b> Expectation</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="moment-generating-and-characteristic-functions.html"><a href="moment-generating-and-characteristic-functions.html"><i class="fa fa-check"></i><b>1.2</b> Moment Generating and Characteristic Functions</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="moment-generating-and-characteristic-functions.html"><a href="moment-generating-and-characteristic-functions.html#moment-generating-functions"><i class="fa fa-check"></i><b>1.2.1</b> Moment Generating Functions</a></li>
<li class="chapter" data-level="1.2.2" data-path="moment-generating-and-characteristic-functions.html"><a href="moment-generating-and-characteristic-functions.html#characteristic-functions"><i class="fa fa-check"></i><b>1.2.2</b> Characteristic Functions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="inequalities.html"><a href="inequalities.html"><i class="fa fa-check"></i><b>1.3</b> Inequalities</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="inequalities.html"><a href="inequalities.html#typical-tail-bound-inequalities"><i class="fa fa-check"></i><b>1.3.1</b> Typical tail bound inequalities</a></li>
<li class="chapter" data-level="1.3.2" data-path="inequalities.html"><a href="inequalities.html#exponential-concentration-inequalities"><i class="fa fa-check"></i><b>1.3.2</b> Exponential concentration inequalities</a></li>
<li class="chapter" data-level="1.3.3" data-path="inequalities.html"><a href="inequalities.html#inequalities-for-expectations"><i class="fa fa-check"></i><b>1.3.3</b> Inequalities for expectations</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="law-of-large-numbers.html"><a href="law-of-large-numbers.html"><i class="fa fa-check"></i><b>1.4</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="1.5" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>1.5</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-2-inference.html"><a href="part-2-inference.html"><i class="fa fa-check"></i>PART 2: Inference</a></li>
<li class="chapter" data-level="2" data-path="sampling-estimating-cdf-and-statistical-functionals.html"><a href="sampling-estimating-cdf-and-statistical-functionals.html"><i class="fa fa-check"></i><b>2</b> Sampling, Estimating CDF and Statistical Functionals</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>2.1</b> Sampling</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="sampling.html"><a href="sampling.html#simple-random-sample"><i class="fa fa-check"></i><b>2.1.1</b> Simple Random Sample</a></li>
<li class="chapter" data-level="2.1.2" data-path="sampling.html"><a href="sampling.html#standard-random-sample"><i class="fa fa-check"></i><b>2.1.2</b> Standard Random Sample</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="statistical-estimation.html"><a href="statistical-estimation.html"><i class="fa fa-check"></i><b>2.2</b> Statistical Estimation</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="statistical-estimation.html"><a href="statistical-estimation.html#point-estimation"><i class="fa fa-check"></i><b>2.2.1</b> Point Estimation</a></li>
<li class="chapter" data-level="2.2.2" data-path="statistical-estimation.html"><a href="statistical-estimation.html#confidence-set"><i class="fa fa-check"></i><b>2.2.2</b> Confidence set</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="constructing-estimators.html"><a href="constructing-estimators.html"><i class="fa fa-check"></i><b>2.3</b> Constructing estimators</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="constructing-estimators.html"><a href="constructing-estimators.html#method-of-moments"><i class="fa fa-check"></i><b>2.3.1</b> Method of Moments</a></li>
<li class="chapter" data-level="2.3.2" data-path="constructing-estimators.html"><a href="constructing-estimators.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>2.3.2</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="empirical-distribution.html"><a href="empirical-distribution.html"><i class="fa fa-check"></i><b>2.4</b> Empirical Distribution</a></li>
<li class="chapter" data-level="2.5" data-path="statistical-functionals.html"><a href="statistical-functionals.html"><i class="fa fa-check"></i><b>2.5</b> Statistical Functionals</a></li>
<li class="chapter" data-level="2.6" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i><b>2.6</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="parametric-inference-parameter-estimation.html"><a href="parametric-inference-parameter-estimation.html"><i class="fa fa-check"></i><b>3</b> Parametric Inference (Parameter Estimation)</a>
<ul>
<li class="chapter" data-level="3.1" data-path="method-of-moments-1.html"><a href="method-of-moments-1.html"><i class="fa fa-check"></i><b>3.1</b> Method of Moments</a></li>
<li class="chapter" data-level="3.2" data-path="method-of-maximum-likelihood.html"><a href="method-of-maximum-likelihood.html"><i class="fa fa-check"></i><b>3.2</b> Method of Maximum Likelihood</a></li>
<li class="chapter" data-level="3.3" data-path="bayesian-approach.html"><a href="bayesian-approach.html"><i class="fa fa-check"></i><b>3.3</b> Bayesian Approach</a></li>
<li class="chapter" data-level="3.4" data-path="expectation-maximization-algorithm.html"><a href="expectation-maximization-algorithm.html"><i class="fa fa-check"></i><b>3.4</b> Expectation-Maximization Algorithm</a></li>
<li class="chapter" data-level="3.5" data-path="unbiased-estimators.html"><a href="unbiased-estimators.html"><i class="fa fa-check"></i><b>3.5</b> Unbiased Estimators</a></li>
<li class="chapter" data-level="3.6" data-path="efficiency-cramer-rao-inequality.html"><a href="efficiency-cramer-rao-inequality.html"><i class="fa fa-check"></i><b>3.6</b> Efficiency: Cramer-Rao Inequality</a></li>
<li class="chapter" data-level="3.7" data-path="sufficiency-and-unbiasedness-rao-blackwell-theorem.html"><a href="sufficiency-and-unbiasedness-rao-blackwell-theorem.html"><i class="fa fa-check"></i><b>3.7</b> Sufficiency and Unbiasedness: Rao-Blackwell Theorem</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>4</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="4.1" data-path="neyman-pearson-lemma.html"><a href="neyman-pearson-lemma.html"><i class="fa fa-check"></i><b>4.1</b> Neyman-Pearson Lemma</a></li>
<li class="chapter" data-level="4.2" data-path="wald-test.html"><a href="wald-test.html"><i class="fa fa-check"></i><b>4.2</b> Wald Test</a></li>
<li class="chapter" data-level="4.3" data-path="likelihood-ratio-test.html"><a href="likelihood-ratio-test.html"><i class="fa fa-check"></i><b>4.3</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="4.4" data-path="comparing-samples.html"><a href="comparing-samples.html"><i class="fa fa-check"></i><b>4.4</b> Comparing samples</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-3-models.html"><a href="part-3-models.html"><i class="fa fa-check"></i>PART 3: Models</a></li>
<li class="chapter" data-level="5" data-path="linear-least-squares.html"><a href="linear-least-squares.html"><i class="fa fa-check"></i><b>5</b> Linear Least Squares</a>
<ul>
<li class="chapter" data-level="5.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>5.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="5.2" data-path="matrix-approach.html"><a href="matrix-approach.html"><i class="fa fa-check"></i><b>5.2</b> Matrix Approach</a></li>
<li class="chapter" data-level="5.3" data-path="statistical-properties.html"><a href="statistical-properties.html"><i class="fa fa-check"></i><b>5.3</b> Statistical Properties</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH 310: Mathematical Statistics (brief notes)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="constructing-estimators" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Constructing estimators<a href="constructing-estimators.html#constructing-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="method-of-moments" class="section level3 hasAnchor" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Method of Moments<a href="constructing-estimators.html#method-of-moments" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(l \in \mathbb{N}\)</span>, the <span class="math inline">\(l\)</span> sample moment is
<span class="math display">\[
   \hat m_l = \frac 1 n \sum_{i=1}^n X_i^l \,.
\]</span></p>
<p>Suppose that we want to determine <span class="math inline">\(k\)</span> different parameters in a parametric model.
The population moments are functions of those parameters:
<span class="math display">\[
\mu_l = \mu_l (\theta_1, \dots, \theta_k) \,.
\]</span></p>
<p>The method of moments says that one can construct parameters <span class="math inline">\(\hat \theta_1, \dots, \hat \theta_k\)</span> by solving
<span class="math display" id="eq:moments">\[\begin{equation}
    \begin{aligned}
        \hat m_1 &amp;= \mu_1 (\hat \theta_1, \dots, \hat \theta_k) \\
        &amp;\vdots\\
        \hat m_k &amp;= \mu_k (\hat \theta_1, \dots, \hat \theta_k) \\
    \end{aligned}
        \tag{2.1}
\end{equation}\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-76" class="example"><strong>Example 2.3  </strong></span>Let <span class="math inline">\(X_1, \dots, X_n \sim N(\theta, \sigma^2)\)</span>.
Construct estimators for the two parameters <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\sigma^2\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-77" class="example"><strong>Example 2.4  </strong></span>Let <span class="math inline">\(X_1, \dots, X_n \sim \mathrm{Binomial}(k,p)\)</span>, i.e.,
<span class="math display">\[ \mathbb{P}(X_i = x) ={k \choose x} p^x (1-p)^{k-x}. \]</span>
Construct estimators for <span class="math inline">\(k\)</span> and <span class="math inline">\(p\)</span>.</p>
</div>
<p>Suppose the model we are considering has <span class="math inline">\(k\)</span> parameters <span class="math inline">\(\theta_j \in \mathbb{R}\)</span>,
where <span class="math inline">\(j = 1, \dots, k\)</span>.</p>
<p>Define a function <span class="math inline">\(g: \mathbb{R}^k \to \mathbb{R}^k\)</span> by
<span class="math display">\[ g(\theta) = \mu, \]</span>
where
<span class="math display">\[\theta = (\theta_1, \dots, \theta_k)\]</span>
and
<span class="math display">\[\mu = (\mu_1, \dots, \mu_k).\]</span></p>
<p>We can rephrase the above construction of the estimators
as solving for <span class="math inline">\(\hat \theta\)</span>, given <span class="math inline">\(\hat \mu\)</span> in the equation
<span class="math display" id="eq:estimator">\[\begin{equation}
\hat \mu = g(\hat \theta) .
\tag{2.2}
\end{equation}\]</span></p>
<p>(Note that <span class="math inline">\(\hat \mu\)</span> and <span class="math inline">\(\hat \theta\)</span> depends on the sample (size))</p>
<p>Two natural questions arise:</p>
<ol style="list-style-type: decimal">
<li><p>Can we solve this equation?</p></li>
<li><p>Are the estimators consistent?</p></li>
</ol>
<p>The answer to the first question is not so obvious.
However, if we can solve the first problem, then the second problem is
somewhat more manageable, given some reasonable assumptions.</p>
<div class="exercise">
<p><span id="exr:unlabeled-div-78" class="exercise"><strong>Exercise 2.5  </strong></span>Suppose that <span class="math inline">\(g:\mathbb{R}^k \to \mathbb{R}^k\)</span> defined above is a bijection with continuous inverse.
Then, for each <span class="math inline">\(\epsilon &gt;0\)</span>, there exists an <span class="math inline">\(N&gt;0\)</span> such that for every <span class="math inline">\(n \geq N\)</span>,</p>
<p><span class="math display">\[\lim_{n\to \infty}\mathbb{P}( |\hat \theta - \bar \theta| ) \geq 1 - 1/ \epsilon.\]</span></p>
<p>That is, <span class="math inline">\(\hat \theta\)</span> is consistent.</p>
</div>
<p>Of course, <span class="math inline">\(g\)</span> is nonlinear generally. So, the assumption that <span class="math inline">\(g\)</span> is a bijection may seem to
be too strong and not too satisfying.
To fix this issue, let’s consider a more general version of the above construction of estimators.</p>
<p>Define a modified version of the estimator <span class="math inline">\(\hat \theta\)</span> as follows</p>
<p><span class="math display">\[ \tilde \theta =
\begin{cases} \hat \theta &amp; \text{if it is solvable } \\
   0 &amp; \text{otherwise}\end{cases}\]</span></p>
<div class="theorem">
<p><span id="thm:unlabeled-div-79" class="theorem"><strong>Theorem 2.3  </strong></span>Suppose that all the moments of the underlying population are finte,
<span class="math inline">\(g\)</span> is of class <span class="math inline">\(C^1\)</span> and that <span class="math inline">\(\det[Dg]\not= 0\)</span>.
For each <span class="math inline">\(\epsilon &gt;0\)</span>,
<span class="math display">\[\lim_{n\to \infty}\mathbb{P}( |\tilde \theta - \bar \theta| &gt; \epsilon ) = 0.\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-80" class="proof"><em>Proof</em>. </span>Let <span class="math inline">\(\epsilon, \alpha &gt;0\)</span>.</p>
<p>From the weak law of large number, there exists <span class="math inline">\(\bar m\)</span> so that <span class="math inline">\(\hat m \to \bar m\)</span>
as <span class="math inline">\(n \to \infty\)</span> in probability.
Note, that <span class="math inline">\(\bar m\)</span> is the list of moments that are generated from the underlying
population, therefore,
<span class="math display">\[\bar m = g (\bar \theta),\]</span>
where <span class="math inline">\(\bar\theta\)</span> is the list of underlying parameters.</p>
<p>By the inverse function theorem, there exists a <span class="math inline">\(\delta &gt;0\)</span> such that:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(g\)</span> is invertible in the ball <span class="math inline">\(B(\bar m, \delta)\)</span>,</p></li>
<li><p><span class="math inline">\(g^{-1}\)</span> is of class <span class="math inline">\(C^1\)</span>,</p></li>
<li><p><span class="math inline">\(g^{-1}(B(\bar m, \delta)) \subseteq B(\bar \theta, \epsilon)\)</span>.</p></li>
</ol>
<p>Let <span class="math inline">\(N\)</span> be such that for every <span class="math inline">\(n &gt; N\)</span>,
<span class="math display">\[\mathbb{P}( |\hat m - \bar m| &lt; \delta) \geq 1 - \alpha. \]</span></p>
<p>Since <span class="math inline">\(|\hat m - \bar m| &lt; \delta\)</span> implies that <span class="math inline">\(\hat\theta\)</span> is uniquely solvable, i.e. 
<span class="math inline">\(\hat\theta = g^{-1}(\hat m)\)</span>,
we have
<span class="math display">\[ \mathbb{P}(| \tilde \theta - \bar \theta | &gt; \epsilon) \leq \mathbb{P}( |\hat m - \bar m| \geq \delta) \leq \alpha. \]</span></p>
<p>Therefore, since <span class="math inline">\(\alpha\)</span> is arbitrary,
<span class="math display">\[\lim_{n\to \infty}\mathbb{P}( |\tilde \theta - \bar \theta| &gt; \epsilon ) = 0,\]</span>
as desired.</p>
</div>
</div>
<div id="maximum-likelihood-estimation" class="section level3 hasAnchor" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> Maximum Likelihood Estimation<a href="constructing-estimators.html#maximum-likelihood-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="definition">
<p><span id="def:unlabeled-div-81" class="definition"><strong>Definition 2.9  </strong></span>Suppose <span class="math inline">\(X_1, \dots, X_n \sim f_\theta\)</span>.
The <em>likelihood</em> function is defined by
<span class="math display">\[ \mathcal{L}_n(\theta) = \prod_{i = 1}^n f (X_i; \theta) \,. \]</span>
The <em>log-likelihood function</em> is defined by
<span class="math display">\[ \ell_n (\theta) h = \ln \mathcal{L}_n (\theta) \,. \]</span></p>
<p>The <em>maximum likelihood estimator</em> MLE, denoted by <span class="math inline">\(\hat \theta_n\)</span>, is the value of
<span class="math inline">\(\theta\)</span> that maximizes <span class="math inline">\(\mathcal{L}_n(\theta)\)</span>.</p>
</div>
<p><strong>Notation.</strong> Another common notation for the likelihood function is
<span class="math display">\[ L(\theta| X) = \mathcal{L}_n(\theta).\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-82" class="example"><strong>Example 2.5  </strong></span>Let <span class="math inline">\(X_1, \dots, X_n\)</span> be sample from <span class="math inline">\(\mathrm{Bernoulli}(p)\)</span>.
Use MLE to find an estimator for <span class="math inline">\(p\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-83" class="example"><strong>Example 2.6  </strong></span>Let <span class="math inline">\(X_1, \dots, X_n\)</span> be sample from <span class="math inline">\(N(\theta, 1)\)</span>.
Use MLE to find an estimator for <span class="math inline">\(\theta\)</span>.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-84" class="exercise"><strong>Exercise 2.6  </strong></span>Let <span class="math inline">\(X_1, \dots, X_n\)</span> be sample from <span class="math inline">\(Uniform(0,\theta)\)</span>, where <span class="math inline">\(\theta &gt;0\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Find the MLE for <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Find an estimator by the method of moments.</p></li>
<li><p>Compute the mean and the variance of the two estimators above.</p></li>
</ol>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-85" class="theorem"><strong>Theorem 2.4  </strong></span>Let <span class="math inline">\(\tau = g(\theta)\)</span> be a bijective function of <span class="math inline">\(\theta\)</span>.
Suppose that <span class="math inline">\(\hat \theta_n\)</span> is the MLE of <span class="math inline">\(\theta\)</span>.
Then <span class="math inline">\(\hat \tau_n = g(\hat \theta_n)\)</span> is the MLE of <span class="math inline">\(\tau\)</span>.</p>
</div>
<p>To discuss about the consistency of the MLE, we define the
Kullback-Leibler distance between two pdf <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span>.</p>
<p><span class="math display">\[ D(f,g) = \int f(x) \ln \left( \frac{f(x)}{g(x)} \right) \, dx.\]</span></p>
<p>Abusing notation, we will write
<span class="math inline">\(D(\theta, \varphi)\)</span> to mean <span class="math inline">\(D(f(x;\theta), f(x;\varphi))\)</span>.</p>
<p>We say that a model <span class="math inline">\(\mathcal{F}\)</span> is <em>identifiable</em> if <span class="math inline">\(\theta \not= \varphi\)</span> implies
<span class="math inline">\(D(\theta, \varphi) &gt; 0\)</span>.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-86" class="theorem"><strong>Theorem 2.5  </strong></span>Let <span class="math inline">\(\theta_{\star}\)</span> denote the true value of <span class="math inline">\(\theta\)</span>. Define
<span class="math display">\[
M_n(\theta)=\frac{1}{n} \sum_i \log \frac{f\left(X_i ; \theta\right)}{f\left(X_i ; \theta_{\star}\right)}
\]</span>
and <span class="math inline">\(M(\theta)=-D\left(\theta_{\star}, \theta\right)\)</span>. Suppose that
<span class="math display">\[
\sup _{\theta \in \Theta}\left|M_n(\theta)-M(\theta)\right| \to 0
\]</span>
in probability
and that, for every <span class="math inline">\(\epsilon&gt;0\)</span>,
<span class="math display">\[
\sup _{\theta:|\theta-\theta,| \geq \epsilon} M(\theta)&lt;M\left(\theta_{\star}\right) .
\]</span></p>
<p>Let <span class="math inline">\(\widehat{\theta}_n\)</span> denote the MLE. Then <span class="math inline">\(\widehat{\theta}_n \to \theta_{\star}\)</span> in probability.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-87" class="exercise"><strong>Exercise 2.7  </strong></span>Let <span class="math inline">\(X_1, \ldots, X_n\)</span> be a random sample from a distribution with density:
<span class="math display">\[ p(x; \theta) = \theta x^{-2}, \quad 0 &lt; \theta \leq x &lt; \infty. \]</span></p>
<ol style="list-style-type: decimal">
<li><p>Find the MLE for <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Find the Method of Moments estimator for <span class="math inline">\(\theta\)</span>.</p></li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-88" class="exercise"><strong>Exercise 2.8  </strong></span>Let <span class="math inline">\(X_1, \ldots, X_n \sim \text{Poisson}(\lambda)\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Find the method of moments estimator, the maximum likelihood estimator, and the Fisher information <span class="math inline">\(I(\lambda)\)</span>.</p></li>
<li><p>Use the fact that the mean and variance of the Poisson distribution are both <span class="math inline">\(\lambda\)</span> to propose two unbiased estimators of <span class="math inline">\(\lambda\)</span>.</p></li>
<li><p>Show that one of these estimators has a larger variance than the other.</p></li>
</ol>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="statistical-estimation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="empirical-distribution.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MathStat.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
